{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical,plot_model\n",
    "\n",
    "from keras.models import Input,Model,Sequential\n",
    "from keras.layers import LSTM,Embedding,Dropout,Activation,Reshape,Dense,GRU,Add,Flatten,concatenate\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>stance_cat</th>\n",
       "      <th>stance_base</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graves least 15 bodies near m...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>danny boyle directing untitled film seth rogen...</td>\n",
       "      <td>3</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hundreds palestinians flee floods gaza israel ...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "      <td>hundreds palestinians evacuated homes sunday m...</td>\n",
       "      <td>0</td>\n",
       "      <td>related</td>\n",
       "      <td>79.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christian bale passes role steve jobs actor re...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>30 year old moscow resident hospitalized wound...</td>\n",
       "      <td>3</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hbo apple talks 15 month apple tv streaming se...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>reuters canadian soldier shot canadian war mem...</td>\n",
       "      <td>3</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spider burrowed tourist stomach chest</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "      <td>fear arachnophobes story bunbury spiderman mig...</td>\n",
       "      <td>1</td>\n",
       "      <td>related</td>\n",
       "      <td>28.301887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  \\\n",
       "0  police find mass graves least 15 bodies near m...      712  unrelated   \n",
       "1  hundreds palestinians flee floods gaza israel ...      158      agree   \n",
       "2  christian bale passes role steve jobs actor re...      137  unrelated   \n",
       "3  hbo apple talks 15 month apple tv streaming se...     1034  unrelated   \n",
       "4              spider burrowed tourist stomach chest     1923   disagree   \n",
       "\n",
       "                                         articleBody  stance_cat stance_base  \\\n",
       "0  danny boyle directing untitled film seth rogen...           3   unrelated   \n",
       "1  hundreds palestinians evacuated homes sunday m...           0     related   \n",
       "2  30 year old moscow resident hospitalized wound...           3   unrelated   \n",
       "3  reuters canadian soldier shot canadian war mem...           3   unrelated   \n",
       "4  fear arachnophobes story bunbury spiderman mig...           1     related   \n",
       "\n",
       "   jaccard_similarity  \n",
       "0            0.000000  \n",
       "1           79.545455  \n",
       "2            0.000000  \n",
       "3            0.000000  \n",
       "4           28.301887  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99944\n",
      "99944\n",
      "Vocabulary Length is 23226\n"
     ]
    }
   ],
   "source": [
    "corpus = np.r_[data['Headline'].values,data['articleBody'].values]\n",
    "print(49972*2)\n",
    "print(len(corpus)) # first 49972 contains the Headline and next 49972 contains the articleBody\n",
    "\n",
    "vocabulary = []\n",
    "for sentence in corpus:\n",
    "    vocabulary.extend(sentence.split(' '))\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocab_length = len(vocabulary)\n",
    "print(\"Vocabulary Length is {0}\".format(vocab_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "max_nb_words = 24000\n",
    "EMBEDDING_DIM = 50\n",
    "MAX_SEQUENCE_LENGTH = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE - ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_docs_headline = [one_hot(sentence,vocab_length) for sentence in data.loc[:,'Headline'].tolist()]\n",
    "padded_docs_headline = pad_sequences(encoded_docs_headline,MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "encoded_docs_body = [one_hot(sentence,vocab_length) for sentence in data.loc[:,'articleBody'].tolist()]\n",
    "padded_docs_body = pad_sequences(encoded_docs_body,MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "\n",
    "labels = to_categorical(data.loc[:,'stance_cat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_headline = Input(shape=[64],name='input_headline')\n",
    "embedding_headline = Embedding(vocab_length,50,input_length = MAX_SEQUENCE_LENGTH)(input_headline)\n",
    "dense_headline = Dense(16,activation='relu')(embedding_headline)\n",
    "\n",
    "input_body = Input(shape=[64],name='input_body')\n",
    "embedding_body = Embedding(vocab_length,50,input_length = MAX_SEQUENCE_LENGTH)(input_body)\n",
    "dense_body = Dense(16,activation='relu')(embedding_body)\n",
    "\n",
    "addition_layer = concatenate([dense_body,dense_headline])\n",
    "flatten = Flatten()(addition_layer)\n",
    "output = Dense(4,activation='sigmoid')(flatten)\n",
    "\n",
    "model_combined = Model(inputs=[input_headline,input_body],outputs=output)\n",
    "\n",
    "model_combined.compile(optimizer = 'adam',loss ='categorical_crossentropy',metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_body (InputLayer)         [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_headline (InputLayer)     [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 64, 50)       1161300     input_body[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 64, 50)       1161300     input_headline[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64, 16)       816         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64, 16)       816         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 32)       0           dense_1[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            8196        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,332,428\n",
      "Trainable params: 2,332,428\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs_headline_train = padded_docs_headline[:int(len(padded_docs_headline)*0.8),:]\n",
    "padded_docs_headline_test = padded_docs_headline[int(len(padded_docs_headline)*0.8):,:]\n",
    "\n",
    "padded_docs_body_train = padded_docs_body[:int(len(padded_docs_body)*0.8),:]\n",
    "padded_docs_body_test = padded_docs_body[int(len(padded_docs_body)*0.8):,:]\n",
    "\n",
    "labels_train = labels[:int(len(labels)*0.8),:]\n",
    "labels_test = labels[int(len(labels)*0.8):,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.6942 - accuracy: 0.7595 - val_loss: 0.4710 - val_accuracy: 0.8209\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.4263 - accuracy: 0.8379 - val_loss: 0.4390 - val_accuracy: 0.8336\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3805 - accuracy: 0.8536 - val_loss: 0.4304 - val_accuracy: 0.8366\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.3733 - accuracy: 0.8525 - val_loss: 0.4275 - val_accuracy: 0.8369\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3604 - accuracy: 0.8578 - val_loss: 0.4349 - val_accuracy: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba5de614c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_combined.fit([padded_docs_headline_train,padded_docs_body_train],labels_train,epochs=5,verbose=1,validation_data=([padded_docs_headline_test,padded_docs_body_test],labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi- Directional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"/home/abhinav/fake_news_challenge/fake_news_challenge/glove\"\n",
    "def setup_embedding_index():\n",
    "    embedding_index=dict()\n",
    "    f = open(os.path.join(GLOVE_DIR,\"glove.6B.50d.txt\"),encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.array(values[1:],dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "    f.close()\n",
    "    return embedding_index\n",
    "embeddings_index = setup_embedding_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3255\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data.loc[:,'Headline'].values)\n",
    "vocab_headline_length = len(tokenizer.word_index)+1\n",
    "encoded_docs= tokenizer.texts_to_sequences(data.loc[:,'Headline'])\n",
    "padded_docs_headline = pad_sequences(encoded_docs, maxlen=16, padding='post')\n",
    "print(vocab_headline_length)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_headline = np.zeros((vocab_headline_length,EMBEDDING_DIM))\n",
    "# words = (list(word_index.keys()))[:max_nb_words]\n",
    "\n",
    "# for word,i in word_index.items():\n",
    "#     if i>=max_nb_words:\n",
    "#         continue\n",
    "#     embedding_vector = embedding_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix_headline[i] = embedding_vector\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_headline[i] = embedding_vector\n",
    "dims = len(embedding_matrix_headline[0])\n",
    "\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23045\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data.loc[:,'articleBody'].values)\n",
    "vocab_body_length = len(tokenizer.word_index)+1\n",
    "encoded_docs= tokenizer.texts_to_sequences(data.loc[:,'Headline'])\n",
    "padded_docs_body = pad_sequences(encoded_docs, maxlen=48, padding='post')\n",
    "print(vocab_body_length)\n",
    "vocab_length = max(vocab_body_length,vocab_headline_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 16)\n",
      "(49972, 48)\n"
     ]
    }
   ],
   "source": [
    "print(padded_docs_headline.shape)\n",
    "print(padded_docs_body.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.fit_on_texts(data.loc[:,'articleBody'].values)\n",
    "# encoded_docs= tokenizer.texts_to_sequences(data.loc[:,'articleBody'])\n",
    "\n",
    "# X_en = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "# X_encoded = np.concatenate((X_encoded,X_en),axis=1)\n",
    "word_index = tokenizer.word_index\n",
    "# num_words = min(max_nb_words,len(word_index))\n",
    "# print('Number of words',num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23044\n"
     ]
    }
   ],
   "source": [
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_body = np.zeros((vocab_body_length,EMBEDDING_DIM))\n",
    "# words = (list(word_index.keys()))[:max_nb_words]\n",
    "\n",
    "# for word,i in word_index.items():\n",
    "#     if i>=max_nb_words:\n",
    "#         continue\n",
    "#     embedding_vector = embedding_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix_body[i] = embedding_vector\n",
    "# dims = len(embedding_matrix_body[0])\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_body[i] = embedding_vector\n",
    "dims = len(embedding_matrix_body[0])\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_headline = Input(shape=[16],name='input_headline')\n",
    "embedding_layer_headline = Embedding(vocab_headline_length,dims,weights=[embedding_matrix_headline],input_length = 16,trainable=False)(input_headline)\n",
    "\n",
    "# lstm_headline = LSTM(units=16)(embedding_headline)\n",
    "\n",
    "input_body = Input(shape=[48],name='input_body')\n",
    "embedding_layer_body = Embedding(vocab_body_length,dims,weights = [embedding_matrix_body],input_length=48,trainable = False)(input_body)\n",
    "# lstm_body = LSTM(units=16)(embedding_layer_body)\n",
    "\n",
    "addition_layer = concatenate([embedding_layer_headline,embedding_layer_body],axis=1)\n",
    "lstm = LSTM(units=64)(addition_layer)\n",
    "drop = Dropout(0.25)(lstm)\n",
    "dense = Dense(64,activation='relu')(drop)\n",
    "# flatten = Flatten()(addition_layer)\n",
    "\n",
    "output = Dense(4,activation='sigmoid')(dense)\n",
    "\n",
    "model_combined_lstm = Model(inputs=[input_headline,input_body],outputs=output)\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = opt)\n",
    "\n",
    "model_combined_lstm.compile(optimizer = sgd,loss ='categorical_crossentropy',metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_headline (InputLayer)     [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_body (InputLayer)         [(None, 48)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 16, 50)       162750      input_headline[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 48, 50)       1152250     input_body[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 50)       0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           29440       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            260         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,348,860\n",
      "Trainable params: 33,860\n",
      "Non-trainable params: 1,315,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_combined_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs_headline_train = padded_docs_headline[:int(len(padded_docs_headline)*0.9),:]\n",
    "padded_docs_headline_test = padded_docs_headline[int(len(padded_docs_headline)*0.9):,:]\n",
    "\n",
    "padded_docs_body_train = padded_docs_body[:int(len(padded_docs_body)*0.9),:]\n",
    "padded_docs_body_test = padded_docs_body[int(len(padded_docs_body)*0.9):,:]\n",
    "\n",
    "labels = to_categorical(data.loc[:,'stance_cat'])\n",
    "\n",
    "labels_train = labels[:int(len(labels)*0.9),:]\n",
    "labels_test = labels[int(len(labels)*0.9):,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1406/1406 [==============================] - 35s 24ms/step - loss: 1.1660 - accuracy: 0.7225 - val_loss: 0.8324 - val_accuracy: 0.7321\n",
      "Epoch 2/10\n",
      "1406/1406 [==============================] - 32s 23ms/step - loss: 0.8261 - accuracy: 0.7314 - val_loss: 0.8034 - val_accuracy: 0.7321\n",
      "Epoch 3/10\n",
      "1406/1406 [==============================] - 33s 23ms/step - loss: 0.8085 - accuracy: 0.7311 - val_loss: 0.7971 - val_accuracy: 0.7321\n",
      "Epoch 4/10\n",
      "1406/1406 [==============================] - 34s 24ms/step - loss: 0.8043 - accuracy: 0.7326 - val_loss: 0.7947 - val_accuracy: 0.7321\n",
      "Epoch 5/10\n",
      "1406/1406 [==============================] - 34s 24ms/step - loss: 0.8059 - accuracy: 0.7289 - val_loss: 0.7938 - val_accuracy: 0.7321\n",
      "Epoch 6/10\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 0.7964 - accuracy: 0.7336 - val_loss: 0.7932 - val_accuracy: 0.7321\n",
      "Epoch 7/10\n",
      "1406/1406 [==============================] - 36s 25ms/step - loss: 0.7961 - accuracy: 0.7343 - val_loss: 0.7929 - val_accuracy: 0.7321\n",
      "Epoch 8/10\n",
      "1406/1406 [==============================] - 33s 24ms/step - loss: 0.7969 - accuracy: 0.7325 - val_loss: 0.7928 - val_accuracy: 0.7321\n",
      "Epoch 9/10\n",
      "1406/1406 [==============================] - 35s 25ms/step - loss: 0.7997 - accuracy: 0.7325 - val_loss: 0.7927 - val_accuracy: 0.7321\n",
      "Epoch 10/10\n",
      "1406/1406 [==============================] - 33s 24ms/step - loss: 0.7981 - accuracy: 0.7324 - val_loss: 0.7927 - val_accuracy: 0.7321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba589f62b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_combined_lstm.fit([padded_docs_headline_train,padded_docs_body_train],labels_train,epochs=10,shuffle=True,verbose=1,validation_data=([padded_docs_headline_test,padded_docs_body_test],labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
